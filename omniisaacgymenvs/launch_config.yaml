configurations:
### PPO
  - pretrain: [True]
  - pretrainer_epochs: [1]
  - random_seed: [42, 3]
  - entropy_loss_scale: [0., 0.0001]
  - learning_rate: [0.0005]
  - ratio_clip: [0.2]
  - lambda_0: [0.1, 0.5]
  - lambda_1: [0.99993]

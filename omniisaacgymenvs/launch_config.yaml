configurations:
### PPO
  - run1:
      pretrain: False
      mini_batches: 4
      reward_shaper: False
      nn_type: SharedNetworks

  - run2:
      pretrain: False
      mini_batches: 4
      value_preprocessor: RunningStandardScaler
      nn_type: SharedNetworks

  - run3:
      pretrain: True
      mini_batches: 4
      reward_shaper: False
      nn_type: SharedNetworks

  - run4:
      pretrain: True
      mini_batches: 4
      value_preprocessor: RunningStandardScaler
      nn_type: SharedNetworks

  - run5:
      pretrain: True
      mini_batches: 4
      nn_type: SharedNetworks
      value_preprocessor: RunningStandardScaler
      learning_rate: 0.001

  - run6:
      pretrain: True
      mini_batches: 4
      value_preprocessor: RunningStandardScaler
      nn_type: SharedNetworks
      learning_rate: 0.0005

  - run7:
      pretrain: True
      mini_batches: 4
      value_preprocessor: RunningStandardScaler
      nn_type: SharedNetworks
      learning_rate: 0.0001

  - run8:
      pretrain: True
      mini_batches: 4
      value_preprocessor: RunningStandardScaler
      nn_type: SharedNetworks
      learning_rate: 0.00005



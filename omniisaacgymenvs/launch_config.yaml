configurations:
### PPO
  - pretrain: [True]
  - lambda_0: [0.1]
  - random_seed: [42, 1, 2]
